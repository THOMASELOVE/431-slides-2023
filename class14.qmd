---
title: "431 Class 14"
author: Thomas E. Love, Ph.D.
date: "2023-10-12"
format:
  revealjs: 
    theme: default
    self-contained: true
    slide-number: true
    footnotes-hover: true
    preview-links: auto
    date-format: iso
    logo: 431-2023-pic.png
    footer: "431 Class 14 | 2023-10-12 | <https://thomaselove.github.io/431-2023/>"
---


## Today's Agenda

- Discussing Quiz 1
- Confidence Intervals for a Population Proportion
    - Five Methods to Accomplish This Task
- Comparing Two Proportions using Independent Samples
    - Standard Epidemiological Format
    - Working with 2x2 Tables

## Today's Packages

```{r}
#| echo: true
#| message: false

library(Epi) # for twoby2() function
library(readxl) # to import an Excel file
library(pwr) # specialized power functions
library(xfun) # for session_info()
library(kableExtra)
library(broom)
library(Hmisc); library(mosaic)
library(janitor); library(naniar)
library(tidyverse)

source("c14/data/Love-boost.R") # for twobytwo() function

theme_set(theme_bw())
```

# Confidence Intervals for a Population Proportion

## Moving on from Means to Proportions

We've focused on creating statistical inferences about a population mean when we have a quantitative outcome. Now, we'll tackle a **categorical** outcome.

We'll estimate a confidence interval around an unknown population proportion, or rate, symbolized with $\pi$, on the basis of a random sample of *n* observations from the population of interest.

The sample proportion is called $\hat{p}$, which is sometimes, unfortunately, symbolized as $p$.

-   This $\hat{p}$ is the sample proportion - not a *p* value.

## An Example from *JAMA Pediatrics*

![](c14/images/NICU1.png)

## Outcome: Change in Management (COM) {.smaller}

The study involved infants ages 0-120 days admitted to an intensive care unit with a suspected genetic disease.

-   For our first example, we focus on a sample of 326 subjects who received whole-genome sequencing testing at some point in the first 60 days after they were enrolled in the study.
-   The outcome of interest is whether or not the subject received a change of management (COM) 60 days after their enrollment.

What can we conclude about the true proportion in the population of infants who meet our study criteria who would have a COM?

## Loading the Data

```{r}
#| echo: true
nicu <- read_excel("c14/data/nicu_seq.xls") |>
  clean_names()

nicu
```

## Our `outcome` data

```{r}
#| echo: true

nicu |> tabyl(outcome) |> adorn_totals() |> adorn_pct_formatting()
```

Our first inferential goal will be to produce a **confidence interval for the true (population) proportion** receiving a COM, across all infants who meet study criteria, based on this sample of 326 infants.

## A Confidence Interval for a Proportion

A 100(1-$\alpha$)% confidence interval for the population proportion $\pi$ can be created by using:

-   the standard normal distribution,
-   the sample proportion, $\hat{p}$, and
-   the standard error of a sample proportion, which is defined as the square root of $\hat{p}$ multiplied by $(1 - \hat{p})$ divided by the sample size, $n$.

## A Confidence Interval for a Proportion

Specifically, that confidence interval estimate is $\hat{p} \pm Z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$

where $Z_{\alpha/2}$ = the value from a standard Normal distribution cutting off the top $\alpha/2$ of the distribution, obtained in R by substituting the desired $\alpha/2$ value into: `qnorm(alpha/2, lower.tail=FALSE)`.

-   *Note*: This interval is reasonably accurate so long as $n \hat{p}$ and $n(1- \hat{p})$ are each at least 5.

## Estimating $\pi$ in the NICU data

-   We'll build a 95% confidence interval for the true population proportion, so $\alpha$ = 0.05
-   We have n = 326 subjects
-   Sample proportion is $\hat{p}$ = .156, since 51/326 = 0.156.

The standard error of that sample proportion will be

$$
\textrm{SE}(\hat{p}) = \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}} = \sqrt{\frac{0.156(1-0.156)}{326}} = 0.020
$$

## Confidence Interval for $\pi$ = Pr(COM)

Our 95% confidence interval for the true population proportion, $\pi$, of infants who have a COM within 60 days is:

$$
\hat{p} \pm Z_{.025} \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}} = 0.156 \pm 1.96 (0.020) = 0.156 \pm 0.039
$$

or (0.117, 0.195).

To verify that $Z_{0.025} = 1.96$...

```{r}
#| echo: true
qnorm(0.025, lower.tail=FALSE)
```

## Likely Accuracy of this CI?

Since $n \hat{p} = (326)(0.156) = 51$ and $n (1 - \hat{p}) = (326)(1-0.156) = 275$ are substantially greater than 5, the CI should be reasonably accurate.

What can we conclude from this analysis?

-   Point estimate of the proportion with COM is 0.156
-   95% CI for population proportion is (0.117, 0.195)

## What is the "margin of error" in this confidence interval?

95% CI for population proportion is (0.117, 0.195)

-   The entire confidence interval has width 0.078 (or 7.8 percentage points.)
-   The margin of error (or half-width) is 0.039, or 3.9 percentage points.

Happily, that's our last "by hand" calculation.

## Using R to estimate a CI for a Proportion

I'll discuss five procedures for estimating a CI for a population proportion. Each can be obtained using the `binom.test()` function from within the `mosaic` package.

For a 95% CI, we use:

```{r}
#| echo: true
#| eval: false
mosaic::binom.test(x = 51, n = 326, p = 0.5, conf.level = 0.95, # defaults
                   ci.method = "XXX")
```

where the appropriate `ci.method` is obtained from the next slide's table.

## Choosing a `ci.method`

| Approach        | `ci.method` to be used                |
|-----------------|---------------------------------------|
| Wald            | `"Wald"`                              |
| Clopper-Pearson | `"Clopper-Pearson"` or `"binom.test"` |
| Score           | `"Score"` or `"prop.test"`            |
| Agresti-Coull   | `"agresti-coull"`                     |
| Plus4           | `"plus4"`                             |

## Approaches 1-2 in `binom.test()`

Each of these five approaches involves an approximation.

1.  **Wald** is the "basic biostatistics" method we just calculated, where we estimate the standard error using the sample proportion and then use the Normal distribution to set the endpoints. The Wald interval is always symmetric, and can dip below 0 or above 1.
2.  **Clopper-Pearson** is used by `stats::binom.test()` in R as well. It guarantees coverage at least as large as the nominal coverage rate, but may produce wider intervals than the other methods.

## Approaches 3-5 in `binom.test()`

3.  **Score** is used by `stats::prop.test()` and creates CIs by inverting p-values from score tests. It can be applied with a continuity correction (use ci.method = `"prop.test"`) or without.
4.  **Agresti-Coull** is the Wald method after adding Z successes and Z failures to the data, where Z is the appropriate quantile for a standard Normal distribution (1.96 for a 95% CI)
5.  **Plus4** is the Wald method after adding 2 successes and 2 failures (so 4 observations) to the data.

## Formulas for these 5 methods?

See Wikipedia's entry: Binomial proportion confidence interval and Chapter 25 of our Course Notes.

## Method 1: The Wald Procedure

```{r}
#| echo: true
method1 <- binom.test(x = 51, n = 326, conf.level = 0.95, ci.method = "Wald")
method1
```

## Tidying up a `binom.test` result

```{r}
#| echo: true
tidy1 <- tidy(method1)

tidy1 |> select(estimate, conf.low, conf.high, statistic, parameter) |> 
  kbl(digits = 4) |> kable_classic(font_size = 28, full_width = F)
```

## Method 2: Clopper-Pearson Procedure

```{r}
#| echo: true
method2 <- binom.test(x = 51, n = 326, conf.level = 0.95, 
                      ci.method = "Clopper-Pearson")

tidy2 <- tidy(method2)
tidy2 |> select(estimate, conf.low, conf.high, statistic, parameter) |> 
  kbl(digits = 4) |> kable_classic(font_size = 28, full_width = F)
```

## Method 3: Score Procedure

```{r}
#| echo: true
method3 <- binom.test(x = 51, n = 326, conf.level = 0.95, 
                   ci.method = "Score")

tidy3 <- tidy(method3)
tidy3 |> select(estimate, conf.low, conf.high, statistic, parameter) |> 
  kbl(digits = 4) |> kable_classic(font_size = 28, full_width = F)
```

## Method 4: Agresti-Coull Procedure

```{r}
#| echo: true
method4 <- binom.test(x = 51, n = 326, conf.level = 0.95, 
                   ci.method = "agresti-coull")

tidy4 <- tidy(method4)
tidy4 |> select(estimate, conf.low, conf.high, statistic, parameter) |> 
  kbl(digits = 4) |> kable_classic(font_size = 28, full_width = F)
```

## Method 5: Plus4 Procedure

```{r}
#| echo: true
method5 <- binom.test(x = 51, n = 326, conf.level = 0.95, 
                   ci.method = "plus4")

tidy5 <- tidy(method5)
tidy5 |> select(estimate, conf.low, conf.high, statistic, parameter) |> 
  kbl(digits = 4) |> kable_classic(font_size = 28, full_width = F)
```

## Comparison of Methods

```{r}
#| echo: true
res1 <- tidy1 |> select(estimate, conf.low, conf.high)
res2 <- tidy2 |> select(estimate, conf.low, conf.high)
res3 <- tidy3 |> select(estimate, conf.low, conf.high)
res4 <- tidy4 |> select(estimate, conf.low, conf.high)
res5 <- tidy5 |> select(estimate, conf.low, conf.high)

res <- bind_rows(res1, res2, res3, res4, res5)
res <- res |> mutate(
  approach = c("Wald", "Clopper-Pearson", "Score", 
               "Agresti-Coull", "Plus4"))
```

## Results with too many decimal places

95% confidence intervals based on x = 51 successes in n = 326 trials.

```{r}
res |> kbl(digits = 5) |> kable_classic(font_size = 28, full_width = F)
```

This is way more precision than we can really justify, but I just want you to see that the five results are all (slightly) different.

## Results after some rounding

95% confidence intervals based on x = 51 successes in n = 326 trials.

```{r}
res |> kbl(digits = 3) |> kable_classic(font_size = 28, full_width = F)
```

Here's a somewhat more plausible rounding approach.

-   Is the distinction between methods important here?

## Plotting the 95% CI Estimates

```{r}
#| echo: true
ggplot(res, aes(x = approach, y = estimate)) +
  geom_point() + geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  coord_flip() + labs(title = "95% CIs for x = 51, n = 326")
```

## What if we ran 90% CIs Instead?

90% CIs based on x = 51 successes in n = 326 trials.

```{r}
#| echo: true
#| output-location: slide

new1 <- tidy(binom.test(x = 51, n = 326, conf.level = 0.9, ci.method = "Wald")) |> 
  select(estimate, conf.low, conf.high) |> mutate(approach = "Wald")
new2 <- tidy(binom.test(x = 51, n = 326, conf.level = 0.9, ci.method = "Clopper-Pearson")) |> 
  select(estimate, conf.low, conf.high) |> mutate(approach = "Clopper-Pearson")
new3 <- tidy(binom.test(x = 51, n = 326, conf.level = 0.9, ci.method = "Score")) |> 
  select(estimate, conf.low, conf.high) |> mutate(approach = "Score")
new4 <- tidy(binom.test(x = 51, n = 326, conf.level = 0.9, ci.method = "agresti-coull")) |> 
  select(estimate, conf.low, conf.high) |> mutate(approach = "Agresti-Coull")
new5 <- tidy(binom.test(x = 51, n = 326, conf.level = 0.9, ci.method = "plus4")) |> 
  select(estimate, conf.low, conf.high) |> mutate(approach = "Plus4")

newres <- bind_rows(new1, new2, new3, new4, new5)

newres |> kbl(digits = 3) |> kable_classic(font_size = 28, full_width = F)
```

## Plotting the 90% CI Estimates

```{r}
ggplot(newres, aes(x = approach, y = estimate)) +
  geom_point() + geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  coord_flip() + labs(title = "90% CIs for x = 51, n = 326")
```

## Estimating Rates More Accurately

Suppose you have some data involving n independent tries, with x successes. The most natural estimate of the "success rate" in the data is x / n. But, strangely enough, it turns out this isn't an entirely satisfying estimator.

Alan Agresti provides substantial motivation for $\frac{x + 2}{n + 4}$ as an alternative. See <http://andrewgelman.com/2007/05/15> for instance. We'll call this a *Bayesian augmentation*.

## When does this augmentation matter?

Estimates with and without the augmentation will be generally comparable, so long as...

a.  the sample size is more than, say, 30 subjects, and/or
b.  the sample probability of the outcome is between 0.1 and 0.9

## Observe 2 successes in 25 trials?

90% CIs based on x = 2 successes in n = 25 trials.

```{r}
anew1 <- tidy(binom.test(x = 2, n = 25, conf.level = 0.9, ci.method = "Wald")) |> select(estimate, conf.low, conf.high) |> mutate(approach = "Wald")
anew2 <- tidy(binom.test(x = 2, n = 25, conf.level = 0.9, ci.method = "Clopper-Pearson")) |> select(estimate, conf.low, conf.high) |> mutate(approach = "Clopper-Pearson")
anew3 <- tidy(binom.test(x = 2, n = 25, conf.level = 0.9, ci.method = "Score")) |> select(estimate, conf.low, conf.high) |> mutate(approach = "Score")
anew4 <- tidy(binom.test(x = 2, n = 25, conf.level = 0.9, ci.method = "agresti-coull")) |> select(estimate, conf.low, conf.high) |> mutate(approach = "Agresti-Coull")
anew5 <- tidy(binom.test(x = 2, n = 25, conf.level = 0.9, ci.method = "plus4")) |> select(estimate, conf.low, conf.high) |> mutate(approach = "Plus4")

anewres <- bind_rows(anew1, anew2, anew3, anew4, anew5)

anewres |> kbl(digits = 3) |> kable_classic(font_size = 28, full_width = F)
```

## 90% CI Estimates for x = 2, n = 25

```{r}
ggplot(anewres, aes(x = approach, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  geom_hline(aes(yintercept = 0), col = "red", lty = "dashed") +
  coord_flip() +
  labs(title = "90% CIs for x = 2, n = 25")
```

## What if x = 0 or x = n?

The **Rule of Three** approach is often used.

-   An approximate 95% CI for the proportion in a setting where x = 0 in n trials is $(0, \frac{3}{n})$

-   An approximate 95% CI for the proportion where x = n in n trials is $(1 - \frac{3}{n}, 1)$

# Comparing Population Proportions

## Comparing Population Proportions {.smaller}

Suppose we compare population proportions $\pi_1$ and $\pi_2$, based on samples of sizes $n_1$ and $n_2$.

1.  The individual observations in exposure group 1 are not linked/matched to individual observations in exposure group 2. (Independent Samples)
2.  Each individual observation in exposure group 1 is linked or matched to a specific observation in exposure group 2. (Paired Samples)

The determination as to whether the study design creates paired or independent samples can be determined without summarizing the data. It's a function of the design, not the responses.

## A Polling Example {.smaller}

-   200 adult Ohio residents agreed to participate in a poll both two months ago and again today. Each of the 200 people met the polling organization's standards for a "likely voter in the 2022 election". 100 of those polled were under the age of 50 and the rest were 50 or older.
-   In between the two polls, a major news event occurred which was relevant to Candidate X.

We asked them the same question at both times: "Are you considering voting for Candidate X?" We are interested in understanding what the data tell us about:

1.  Were people under age 50 more likely to be considering Candidate X than people ages 50 and higher?
2.  Were people more likely to be considering Candidate X after the news event than before?

Which of these uses *independent* samples, and which *paired* samples?

# Comparing Proportions using Independent Samples

## Visual Abstract: NICU Sequencing Paper

![](c14/images/NICU_abstract.png)

## NICU Sequencing Example

Let's compare the proportion who have a COM between:

-   Group 1: infants tested early (15 d after enrollment)
-   Group 2: infants tested later (60 d after enrollment)

```{r}
#| echo: true
nicu |> count(interv, outcome)
```

-   How might we rearrange this information? Exposure? Outcome?

## The Table We'd Like To Get To

Let's compare the proportion who have a COM between:

-   Group 1: infants tested early (at 15 d)
-   Group 2: infants tested later (delayed to 60 d)

### Standard Epidemiological Format

-   rows are the exposure
-   columns are the outcome

What do we want in our setting?

## Our Goal: Standard Epidemiological Format

-   exposure is *intervention* (15 or 60 days)
-   columns are *outcome* category (COM, No COM)

```{=html}
<!-- -->
```

                     COM       No COM
    Early (15 d)      a          b
    Delayed (60 d)    c          d

## Our 2 x 2 Table

```{r}
#| echo: true
nicu |> tabyl(interv, outcome)
```

-   Is this in standard epidemiological format, with the rows indicating the exposure, and the columns indicating the outcome, and the correct count in the top left cell?

## Switching the Rows

We want Early (15) to come first, before Delayed (60):

```{r}
#| echo: true
nicu <- nicu |> mutate(interv = fct_relevel(interv, "Early (15)"))

nicu |> tabyl(interv, outcome)
```

## Adding Totals

```{r}
#| echo: true
nicu |> tabyl(interv, outcome) |> 
  adorn_totals(where = c("row", "col"))
```

-   How many subjects do we have in each exposure group?
-   How many subjects fall into each outcome group?

## Augmenting the Table

Can we augment the table to help us understand:

-   What is the probability of achieving each of the two possible outcomes?
-   How do the outcome probabilities differ by exposure group?

```{r}
#| echo: true
#| output-location: slide
nicu |> tabyl(interv, outcome) |> 
  adorn_totals(where = c("row", "col")) |>
  adorn_percentages(denom = "row") |>
  adorn_pct_formatting(digits = 1) |>
  adorn_ns(position = "front")
```

## Why am I using `denom = "row"` here?

> Among these subjects, compare the proportion of early (15 d) tested infants with COM to the proportion of late (60 d) tested infants with COM.

-   What are the sample estimates for the two rates I am comparing?

## 2 x 2 Table: Comparing Probabilities

|      --      |  COM | No COM | *Total* |
|:------------:|-----:|-------:|--------:|
|  Early (15)  |   34 |    127 |   *161* |
| Delayed (60) |   17 |    148 |   *165* |
|   *Total*    | *51* |  *275* |   *326* |

-   Pr(COM \| Early) = 34/161 = `r round_half_up(34/161, 3)`
-   Pr(COM \| Delayed) = 17/165 = `r round_half_up(17/165, 3)`
-   The ratio of those two probabilities (risks) is `r round_half_up(34/161, 3)`/`r round_half_up(17/165, 3)` = `r round((34/161)/(17/165), 3)`.

## CI for the Relative Risk?

Can we build a confidence interval for the relative risk of COM now in the early tested infants as compared to the delayed tested infants?

-   The difference in those risks is `r round_half_up(34/161, 3)` - `r round_half_up(17/165, 3)` = `r round_half_up(34/161 - 17/165, 3)`.

How about a confidence interval for the risk difference, too?

## 2 x 2 NICU Table: Odds Ratio

|      --      |  COM | No COM | *Total* |
|:------------:|-----:|-------:|--------:|
|  Early (15)  |   34 |    127 |   *161* |
| Delayed (60) |   17 |    148 |   *165* |
|   *Total*    | *51* |  *275* |   *326* |

-   Odds = Probability / (1 - Probability)
-   Sample Odds of COM if Early = $\frac{34/161}{1 - (34/161)}$ = `r round_half_up((34/161)/(1-(34/161)), 3)`
-   Sample Odds of COM if Delayed = $\frac{17/165}{1 - (17/165)}$ = `r round_half_up((17/165)/(1-(17/165)), 3)`
-   Ratio of these two Odds are `r round_half_up(((34/161)/(1-(34/161))) / ((17/165)/(1-(17/165))),3)`.

## In a 2x2 table, odds ratio = cross-product ratio.

-   Here, the cross-product estimate = $\frac{34*148}{17*127}$ = `r round_half_up(34*148/(17*127),3)`.

Can we build a confidence interval for the population odds ratio for COM given "early" as compared to "delayed" testing?

## Using `twoby2` from the `Epi` package

Once we have set up the factors for `interv` and `outcome` so that the table we produce is in standard epidemiological format, we can plug it into the `twoby2` function from the `Epi` package.

## Using `twoby2` from the `Epi` package

```{r}
#| echo: true
twoby2(table(nicu$interv, nicu$outcome))
```

## Using `twobytwo` from the `Love-boost.R` script

|      --      |  COM | No COM | *Total* |
|:------------:|-----:|-------:|--------:|
|  Early (15)  |   34 |    127 |   *161* |
| Delayed (60) |   17 |    148 |   *165* |
|   *Total*    | *51* |  *275* |   *326* |

Code we need is:

```{r}
#| echo: true
#| output-location: slide
twobytwo(34, 127, 17, 148,  # note order of counts
      "Early", "Delayed", # names of the rows
      "COM", "NoCOM",  # names of the columns
      conf.level = 0.99)  # default is 95% confidence
```

## Another Way to Create The Table

Suppose we didn't have the data, just the visual abstract.

```{r}
#| echo: true

t1 <- matrix(c(34, 127, 17, 148), byrow = TRUE, nrow = 2)
rownames(t1) <- c("Early", "Delayed")
colnames(t1) <- c("COM", "No_COM")
addmargins(t1)
```

## Hypothesis Testing?

The hypotheses being compared can be thought of in several ways...

-   $H_0$: $\pi_1 = \pi_2$, vs. $H_A$: $\pi_1 \neq \pi_2$.
-   $H_0$: Pr(COM \| Early) = Pr(COM \| Delayed) vs. $H_A$: Pr(COM \| Early) $\neq$ Pr(COM \| Delayed).
-   $H_0$: rows and columns of the table are *independent*, in that the probability of COM in each row is the same vs. $H_A$: the rows and columns of the table are *associated*.

## P values in twoby2 output?

```
Exact P-value: 0.0092 
Asymptotic P-value: 0.0083 
```

-   The `Exact P-value` comes from Fisher's exact test, and is technically exact only if we treat the row and column totals as being fixed.
-   The `Asymptotic P-value` comes from a Pearson $\chi^2$ test.
-   Neither approach is helpful if we don't have sufficient data to justify inference in the first place.

## Bayesian Augmentation in a 2x2 Table?

Original command:

```{r}
#| echo: true
#| eval: false
twobytwo(34, 127, 17, 148, "Early", "Delayed", "COM", "NoCOM", 
         conf.level = 0.99)
```

Bayesian augmentation approach: Add two successes and add two failures in each row...

```{r}
#| echo: true
#| output-location: slide
twobytwo(34+2, 127+2, 17+2, 148+2,  "Early", "Delayed", "COM", "NoCOM", 
      conf.level = 0.99)  
```

## Tuberculosis Prevalence in IV Drug Users

Suppose now that we are investigating factors affecting tuberculosis prevalence among intravenous drug users.

-   Among 97 individuals who admit to sharing needles,
    -   24 (24.7%) had a positive tuberculin skin test result.
-   Among 161 drug users who deny sharing needles,
    -   28 (17.4%) had a positive test result.

What does the 2x2 table look like?

## Tuberculosis Prevalence In IV Drug Users

The 2x2 Table is...

             TB+   TB-
    share     24    73
    don't     28   133

-   rows describe needle sharing, columns describe TB test result
-   row 1 people who share needles: 24 TB+, and 97-24 = 73 TB-
-   row 2 people who don't share: 28 TB+ and 161-28 = 133 TB-

## `twobytwo` (with Bayesian Augmentation)

To start, we'll test the null hypothesis that the population proportions of intravenous drug users who have a positive tuberculin skin test result are identical for those who share needles and those who do not.

$$
H_0: \pi_{share} = \pi_{donotshare} \\
H_A: \pi_{share} \neq \pi_{donotshare}
$$

We'll use the Bayesian augmentation.

## `twobytwo` (with Bayesian Augmentation)

```{r}
#| echo: true
twobytwo(24+2, 73+2, 28+2, 133+2, 
         "Sharing", "Not Sharing", 
         "TB test+", "TB test-")
```

## Session Information

```{r}
#| echo: true
session_info()
```