---
title: "431 Class 22"
author: Thomas E. Love, Ph.D.
date: "2023-11-16"
format:
  revealjs: 
    theme: default
    self-contained: true
    slide-number: true
    footnotes-hover: true
    preview-links: auto
    date-format: iso
    logo: 431-2023-pic.png
    footer: "431 Class 22 | 2023-11-16 | <https://thomaselove.github.io/431-2023/>"
---

## Today's Agenda

1. It's Just a Linear Model
2. What exactly is R doing if you ignore missing values when fitting models?
    - What does `type.convert()` do?
    - `na.omit` vs. `na.exclude` vs. `na.delete`
3. Use multiple imputation to deal with missing data in fitting a linear regression with `lm` using the `mice` package. 

(MICE = Multiple Imputation through Chained Equations)

## Today's Packages

```{r}
#| echo: true
#| message: false

library(janitor)
library(naniar)
library(broom)
library(knitr)
library(kableExtra)
library(car)
library(GGally)
library(mice)
library(mitml)
  # mice = multiple imputation through chained equations
library(xfun)
library(tidyverse)

theme_set(theme_bw())
```

# It's Just a Linear Model

## Common Statistical Tests are Linear Models

Jonas Kristoffer Lindelov has built up a terrific resources to explain this at

<https://lindeloev.github.io/tests-as-linear/>

What's the point?

---

![](c22/figures/ijalm.png)

## Consider Study 1 from Project B.

- Analysis A. Compare two means/medians using paired samples
  - This is a linear model. See Section 4.2 of [Lindelov](https://lindeloev.github.io/tests-as-linear/)
  
![](c22/figures/lind_A.png)

## Project B Study 1?

- Analysis B. Compare two means/medians using independent samples
  - This is a linear model, and not just for the t test. See Section 5 of [Lindelov](https://lindeloev.github.io/tests-as-linear/)
- Analysis C. Compare 3-6 means/medians using independent samples
  - ANOVA is obviously a linear model, but actually we can generate (essentially) the Kruskal-Wallis this way, too. See Section 6.1 of [Lindelov](https://lindeloev.github.io/tests-as-linear/)
  
## Project B Study 1?

- Analysis D. Create and analyze a 2x2 table
  - Yes, the chi-square test of independence can emerge from a linear model. See Section 7.2 of [Lindelov](https://lindeloev.github.io/tests-as-linear/)
- Analysis E. Create and analyze a JxK table, where $2 \leq J \leq 5$ and $3 \leq K \leq 5$
  - Linear model, as in the 2x2 case. See Section 7.2 of [Lindelov](https://lindeloev.github.io/tests-as-linear/)

Analyses D-E are more commonly thought about in the context of generalized linear models, as we'll see in 432.

# What happens if you fit a regression model without doing anything at all about missing data?

## What happens if you ignore NAs?

Let's open a small, simulated data set with 100 subjects and some missing values.

```{r}
#| echo: true
#| message: false

sim1 <- read_csv("c22/data/c22_sim1.csv") |>
    type.convert(as.is = FALSE, na.strings = "NA") 

head(sim1)
```

## What does `type.convert()` do? {.smaller}

Tries to convert each column (individually) to either logical, integer, numeric, complex or (if a character vector) to factor.

- The first type (from that list) that can accept all non-missing values is chosen.
- If all values are missing, the column is converted to logical.
- Columns containing just `F`, `T`, `FALSE`, `TRUE` or `NA` values are made into logical.
- Use the `na.strings` parameter to add missing strings (default = `"NA"`)
- `as.is = FALSE` converts characters to factors. `as.is = TRUE` is the default.

## Our `sim1` data

Variable | Description
-------- | ------------------------------------------
`subject` | Subject identifier
`out_q`   | Quantitative outcome
`out_b`   | Binary outcome with levels Yes, No
`pred1`   | Predictor 1 (quantitative)
`pred2`   | Predictor 2 (also quantitative)
`pred3`   | Predictor 3 (categories are Low, Middle, High)

- Clean up the factors?

## Cleaning up `subject` and `pred3`

```{r}
#| echo: true

sim1 <- sim1 |>
    mutate(subject = as.character(subject),
           pred3 = fct_relevel(pred3, "Low", "Middle"))

sim1 |> tabyl(pred3, out_b)
```

## How much missingness do we have?

```{r}
#| echo: true
#| warning: false
#| fig-height: 5
gg_miss_var(sim1)
```

## How much missingness do we have?

```{r}
#| echo: true
miss_var_summary(sim1)
```

```{r}
#| echo: true
n_miss(sim1)
```


## How much missingness do we have?

```{r}
#| echo: true
prop_complete_case(sim1)
```

```{r}
#| echo: true
miss_case_table(sim1)
```

## Suppose we run a linear regression

without dealing with the missing data, so that we run:

```{r}
#| echo: true
mod1 <- lm(out_q ~ pred1 + pred2 + pred3, data = sim1)
summary(mod1)
```

How can we tell how many observations will be used?

## What happens when we run a regression model?

```{r}
#| echo: true
mod1 <- lm(out_q ~ pred1 + pred2 + pred3, data = sim1)

anova(mod1)
```

- How many observations were used to fit this model?

## Another way to see this

```{r}
#| echo: true
glance(mod1) |> select(1:6)
```

```{r}
#| echo: true
glance(mod1) |> select(7:12)
```

## How could we have known this would be 70, in advance?

```{r}
#| echo: true
sim1 |> select(out_q, pred1, pred2, pred3) |> 
    miss_case_table()
```


## Which observations were not used?

```{r}
#| echo: true
summary(mod1)$na.action
```

- A potentially more useful `na.action` setting in `lm` is `na.exclude` which pads out predicted values and residuals with NAs instead of omitting the 30 observations listed above.

```
lm(out_q ~ pred1 + pred2 + pred3, 
      data = sim1, na.action = na.exclude)
```

## Predictions from `mod1` with `na.omit` and `na.exclude`

```{r}
#| echo: true
mod1 <- lm(out_q ~ pred1 + pred2 + pred3, data = sim1)
               ## note: by default na.action = na.omit here
head(predict(mod1))
```

```{r}
#| echo: true
mod1_e <- lm(out_q ~ pred1 + pred2 + pred3, data = sim1,
             na.action = na.exclude)
head(predict(mod1_e))
```

# Multiple Imputation: Potential and Pitfalls

## Sterne et al. 2009 *BMJ*  {.smaller}

Multiple imputation for missing data in epidemiological and clinical research: potential and pitfalls

> In this article, we review the reasons why missing data may lead to bias and loss of information in epidemiological and clinical research. We discuss the circumstances in which multiple imputation may help by reducing bias or increasing precision, as well as describing potential pitfalls in its application. Finally, we describe the recent use and reporting of analyses using multiple imputation in general medical journals, and suggest guidelines for the conduct and reporting of such analyses.

- https://www.bmj.com/content/338/bmj.b2393

**Note**: The next 7 slides are derived from Sterne et al.

## An Example from Sterne et al. {.smaller}

Consider, for example, a study investigating the association of systolic blood pressure with the risk of subsequent coronary heart disease, in which data on systolic blood pressure are missing for some people. 

The probability that systolic blood pressure is missing is likely to:

- decrease with age (doctors are more likely to measure it in older people), 
- decrease with increasing body mass index, and 
- decrease with history of smoking (doctors are more likely to measure it in people with heart disease risk factors or comorbidities). 

If we assume that data are missing at random and that we have systolic blood pressure data on a representative sample of individuals within strata of age, smoking, body mass index, and coronary heart disease, then we can use multiple imputation to estimate the overall association between systolic blood pressure and coronary heart disease.

## Missing Data Mechanisms {.smaller}

- **Missing completely at random** There are no systematic differences between the missing values and the observed values. 
    - For example, blood pressure measurements may be missing because of breakdown of an automatic sphygmomanometer.
- **Missing at random** Any systematic difference between the missing and observed values can be explained by other observed data. 
    - For example, missing BP measurements may be lower than measured BPs but only because younger people more often have a missing BP.
- **Missing not at random** Even after the observed data are taken into account, systematic differences remain between the missing values and the observed values. 
    - For example, people with high BP may be more likely to have headaches that cause them to miss clinic appointments.

"Missing at random" is an **assumption** that justifies the analysis, and is not a property of the data.

## Trouble: Data missing not at random {.smaller}

Sometimes, it is impossible to account for systematic differences between missing and observed values using the available data.

- In such (MNAR) cases, multiple imputation may give misleading results. 
    - Those results can be either more or less misleading than a complete case analysis. 
- For example, consider a study investigating predictors of depression. 
    - If individuals are more likely to miss appointments because they are depressed on the day of the appointment, then it may be impossible to make the MAR assumption plausible, even if a large number of variables is included in the imputation model.

Where complete cases and multiple imputation analyses give different results, the analyst should attempt to understand why, and this should be reported in publications.

## What if the data are MCAR? {.smaller}

If we assume data are MAR, then unbiased and statistically more powerful analyses (compared with analyses based on complete cases) can generally be done by including individuals with incomplete data.

There are circumstances in which analyses of **complete cases** will not lead to bias.

- Missing data in predictor variables do not cause bias in analyses of complete cases if the reasons for the missing data are unrelated to the outcome. 
    - In such cases, imputing missing data may lessen the loss of precision and power resulting from exclusion of individuals with incomplete predictor variables but are not required in order to avoid bias.

## Stages of Multiple Imputation (1 of 2) {.smaller}

> Multiple imputation ... aims to allow for the uncertainty about the missing data by creating several different plausible imputed data sets and appropriately combining results obtained from each of them.

The first stage is to create multiple copies of the dataset, with the missing values replaced by imputed values. 

- The imputation procedure must fully account for all uncertainty in predicting the missing values by injecting appropriate variability into the multiple imputed values; we can never know the true values of the missing data.

Note that single Imputation of missing values usually causes standard errors to be too small, since it fails to account for the fact that we are uncertain about the missing values.


## Stages of Multiple Imputation (2 of 2) {.smaller}

The second stage is to use standard statistical methods to fit the model of interest to each of the imputed datasets. 

- Estimated associations in each of the imputed datasets will differ because of the variation introduced in the imputation of the missing values, and they are only useful when averaged together to give overall estimated associations. 
- Standard errors are calculated using Rubin's rules, which take account of the variability in results between the imputed datasets, reflecting the uncertainty associated with the missing values.
- Valid inferences are obtained because we are averaging over the distribution of the missing data given the observed data.

# Comparing Two Linear Models including Multiple Imputation

## Framingham data

```{r}
#| echo: true
fram_raw <- read_csv("c22/data/framingham.csv", show_col_types = FALSE) |>
    clean_names() 

dim(fram_raw)
n_miss(fram_raw)
```

- See https://www.framinghamheartstudy.org/ for more details.

## Codebook for Today {.smaller}

Variable | Description
-------: | ------------------------------------------------
`educ` | four-level factor: educational attainment
`smoker` | 1 = current smoker at examination time, else 0
`sbp` | systolic blood pressure (mm Hg)
`obese` | 1 if subject's `bmi` is 30 or higher, else 0
`glucose` | blood glucose level in mg/dl

- The variables describe adult subjects who were examined at baseline and then followed for ten years to see if they developed incident coronary heart disease during that time. 

## fram_sub Tibble for Today

```{r}
#| echo: true
fram_sub <- fram_raw |>
    mutate(educ = fct_recode(factor(education), 
                          "Some HS" = "1",
                          "HS grad" = "2",
                          "Some Coll" = "3",
                          "Coll grad" = "4")) |>
    mutate(obese = as.numeric(bmi >= 30)) |>
    rename(smoker = "current_smoker",
           sbp = "sys_bp") |>
    mutate(subj_id = as.character(subj_id)) |>
    select(sbp, educ, smoker, obese, glucose, subj_id)

dim(fram_sub)
```


## Which variables are missing data?

```{r}
#| echo: true
#| warning: false
#| fig-height: 4
gg_miss_var(fram_sub)
```

## Today's Goal

Use linear regression to predict `sbp` using two different models, in each case accounting for missingness via multiple imputation, where the predictors of interest are `glucose`, `obese`, `educ`,  and `smoker`.

## Consider a transformation?

```{r}
#| echo: true
with(fram_sub, car::boxCox(sbp ~ glucose + obese + educ + smoker))
```

## Create a new outcome variable

```{r}
#| echo: true
fram_sub <- fram_sub |>
  mutate(inv_sbp = 1000 / sbp)

summary(1/fram_sub$sbp)
summary(fram_sub$inv_sbp)
```


## Scatterplot Matrix (no imputation)

```{r}
#| echo: true
#| message: false
#| warning: false
ggpairs(fram_sub |> select(glucose, obese, educ, smoker, inv_sbp))
```

## Track missingness with shadow

```{r}
#| echo: true
fram_sub_sh <- bind_shadow(fram_sub)

head(fram_sub_sh)
```

## Our Two Models

Model 2: predict 1000/`sbp` using `glucose` and `obese`.

Model 4: predict 1000/`sbp` using `glucose`, `obese`, `educ`,  and `smoker`.

## Model 2 (CC): 2 predictors

Suppose we ignore the missingness and just run the model on the data with complete information on `inv_sbp`, `glucose` and `obese`.

```{r}
#| echo: true
m2_cc <- with(fram_sub_sh, lm(inv_sbp ~ glucose + obese))

tidy(m2_cc, conf.int = TRUE, conf.level = 0.95) |> select(-statistic) |>
    kable(digits = 3) |> kable_styling(font_size = 28)
```

## Edited Summary of Model 2 (CC)

```{r}
#| echo: true
#| eval: false
summary(m2_cc)   ## we'll just look at the bottom
```

```
Residual standard error: 1.14 on 3833 degrees of freedom
  (402 observations deleted due to missingness)
Multiple R-squared:  0.05531,	Adjusted R-squared:  0.05481 
F-statistic: 112.2 on 2 and 3833 DF,  p-value: < 2.2e-16
```

```{r}
#| echo: true
glance(m2_cc) |>
    select(nobs, r.squared, adj.r.squared, AIC, BIC) |>
    kable(digits = c(0, 4, 4, 0, 0)) |> kable_styling(font_size = 28)
```

## Model 4 (CC): 4 predictors

```{r}
#| echo: true
m4_cc <- lm(inv_sbp ~ glucose + obese + smoker + educ, data = fram_sub_sh)

tidy(m4_cc, conf.int = TRUE) |> select(-statistic) |>
    kable(digits = 3) |> kable_styling(font_size = 28)
```

## Edited Summary of Model 4 (CC)

```{r}
#| echo: true
#| eval: false
summary(m4_cc)          ## we'll just look at the bottom
```

```
Residual standard error: 1.126 on 3733 degrees of freedom
  (498 observations deleted due to missingness)
Multiple R-squared:  0.07919,	Adjusted R-squared:  0.07771 
F-statistic:  53.5 on 6 and 3733 DF,  p-value: < 2.2e-16
```

```{r}
#| echo: true
glance(m4_cc) |>
    select(nobs, r.squared, adj.r.squared, AIC, BIC) |>
    kable(digits = c(0, 4, 4, 0, 0)) |> kable_styling(font_size = 28)
```

## Variables used in our models 2 and 4

```{r}
#| echo: true
miss_var_summary(fram_sub)
```

- Are we missing data on our outcome for these models?

## Create multiple imputations

How many subjects have complete / missing data that affect this model?

```{r}
#| echo: true
pct_complete_case(fram_sub)
pct_miss_case(fram_sub)
```

### Let's create 15 imputed data sets. (Why 15?)

```{r}
#| echo: true
set.seed(431431)
fram_mice24 <- mice(fram_sub, m = 15, printFlag = FALSE)
```

- Using `printFlag = FALSE` eliminates a lot of unnecessary (and not particularly informative) output.

## Summary of Imputation Process {.smaller}

```{r}
#| echo: true
summary(fram_mice24)
```

- See Heymans and Eekhout sections 4.6 - 4.14 for more information.

## Imputation Options within `mice` {.smaller}

Default methods include:

- `pmm` predictive mean matching (default choice for quantitative variables)
- `logreg` logistic regression (default for binary categorical variables)
- `polyreg` polytomous logistic regression (for nominal multi-categorical variables)
- `polr` proportional odds logistic regression (for ordinal categories)

but there are `cart` methods and many others available, too.

## What should we include in an imputation model? {.smaller}

1. If things you are imputing are not Normally distributed, this can pose special challenges, and either a transformation or choosing an imputation method which is robust to these concerns is helpful.
2. Include the outcome when imputing predictors. It causes you to conclude the relationship is weaker than it actually is, if you don't.
3. The MAR assumption may only be reasonable when a certain variable is included in the model.
    - As a result, it's usually a good idea to include as wide a range of variables in imputation models as possible. The concerns we'd have about parsimony in outcome models don't apply here.

## Store one (or more) of the imputed data sets

This will store the fifth imputed data set in `imp_5`.

```{r}
#| echo: true
imp_5 <- complete(fram_mice24, 5) |> tibble()

dim(imp_5)
n_miss(imp_5)
```

## Run Model 2 on each imputed data frame

```{r}
#| echo: true
m2_mods <- with(fram_mice24, lm(inv_sbp ~ glucose + obese))
```

```
> summary(m2_mods)
# A tibble: 45 Ã— 6
   term        estimate std.error statistic  p.value  nobs
   <chr>          <dbl>     <dbl>     <dbl>    <dbl> <int>
 1 (Intercept)  8.30     0.0623      133.   0         4238
 2 glucose     -0.00571  0.000728     -7.84 5.77e-15  4238
 3 obese       -0.709    0.0525      -13.5  1.27e-40  4238
 4 (Intercept)  8.31     0.0626      133.   0         4238
 5 glucose     -0.00583  0.000733     -7.95 2.45e-15  4238
 6 obese       -0.708    0.0526      -13.5  1.50e-40  4238
# ... with 39 more rows
```

- 3 coefficients in each model, times 15 imputations = 45 rows.

## More detailed regression results?

Consider working with the analysis done on the 4th imputed data set (of the 15 created)...

```{r}
#| echo: true
m2_a4 <- m2_mods$analyses[[4]]
tidy(m2_a4) |> kable(digits = 3) |> kable_styling(font_size = 28)
```

## Pool Results across the 15 imputations

```{r}
#| echo: true
m2_pool <- pool(m2_mods)
summary(m2_pool, conf.int = TRUE, conf.level = 0.95)
```

## Model 2 (Complete Cases vs. MI)

```{r}
#| echo: true
tidy(m2_cc, conf.int = T) |> kable(digits = 3) |> kable_styling(font_size = 28)
```

```{r}
#| echo: true
summary(m2_pool, conf.int = TRUE, conf.level = 0.95) |>
    select(-df) |> kable(digits = 3) |> kable_styling(font_size = 28)
```

## More Details on MI Modeling

```{r}
#| echo: true
m2_pool
```

Definitions of these terms are in the `mipo` help file.

- `riv` = relative increase in variance attributable to non-response
- `fmi` = fraction of missing information due to non-response

## Model 4 run on each imputed data frame

```{r}
#| echo: true
m4_mods <- with(fram_mice24, lm(inv_sbp ~ glucose + 
                              obese + smoker + educ))

summary(m4_mods)
```

## Pool Results across the 15 imputations

```{r}
#| echo: true
m4_pool <- pool(m4_mods)

summary(m4_pool, conf.int = TRUE, conf.level = 0.95) |>
    select(-df) |> kable(digits = 3) |> kable_styling(font_size = 28)
```

## Complete Cases Result (Model 4) {.smaller}

```{r}
#| echo: true
tidy(m4_cc, conf.int = TRUE, conf.level = 0.95) |> 
    kable(digits = 3) |> kable_styling(font_size = 28)
```

## Additional MI Modeling Details

```{r}
#| echo: true
m4_pool
```

## Estimate $R^2$ and Adjusted $R^2$

```{r}
#| echo: true
pool.r.squared(m2_mods)
pool.r.squared(m2_mods, adjusted = TRUE)

pool.r.squared(m4_mods)
pool.r.squared(m4_mods, adjusted = TRUE)
```

## Tests of Nested Fits after imputation

The models must be nested (same outcome, one set of predictors is a subset of the other) for this to be appropriate. 

```{r}
#| echo: true
fit4 <- with(fram_mice24, 
          expr = lm(inv_sbp ~ glucose + obese + smoker + educ))
fit2 <- with(fram_mice24, 
          expr = lm(inv_sbp ~ glucose + obese))
```

## Comparing Model 4 to Model 2 fits

We'll use the Wald test after a linear regression fit.

```{r}
#| echo: true
D1(fit4, fit2)
```

Could also use a likelihood ratio test.

```{r}
#| echo: true
D3(fit4, fit2)
```

## Residual Plots for `mod4` (6th imputation)

```{r}
#| echo: true
par(mfrow = c(1,2))
plot(m4_mods$analyses[[6]], which = c(1:2))
```

## Residual Plots for `mod4` (6th imputation)

```{r}
#| echo: true
par(mfrow = c(1,2))
plot(m4_mods$analyses[[6]], which = c(3,5))
par(mfrow = c(1,1))
```

## Residual Plots for `mod4` (1st imputation)

```{r}
#| echo: true
par(mfrow = c(1,2))
plot(m4_mods$analyses[[1]], which = c(1:2))
```

## Residual Plots for `mod4` (1st imputation)

```{r}
#| echo: true
par(mfrow = c(1,2))
plot(m4_mods$analyses[[1]], which = c(3,5))
par(mfrow = c(1,1))
```

# Guidelines for Reporting

## Guidelines for reporting, I (Sterne et al.) {.smaller}

How should we report on analyses potentially affected by missing data?

- Report the number of missing values for each variable of interest, or the number of cases with complete data for each important component of the analysis. Give reasons for missing values if possible, and indicate how many individuals were excluded because of missing data when reporting the flow of participants through the study. If possible, describe reasons for missing data in terms of other variables (rather than just reporting a universal reason such as treatment failure.)
- Clarify whether there are important differences between individuals with complete and incomplete data, for example, by providing a table comparing the distributions of key exposure and outcome variables in these different groups
- Describe the type of analysis used to account for missing data (eg, multiple imputation), and the assumptions that were made (eg, missing at random)

## Guidelines for reporting, II (Sterne et al.) {.smaller}

How should we report on analyses that involve multiple imputation?

- Provide details of the imputation modeling (software used, key settings, number of imputed datasets, variables included in imputation procedure, etc.)
- If a large fraction of the data is imputed, compare observed and imputed values.
- Where possible, provide results from analyses restricted to complete cases, for comparison with results based on multiple imputation. If there are important differences between the results, suggest explanations.
- It is also desirable to investigate the robustness of key inferences to possible departures from the missing at random assumption, by assuming a range of missing not at random mechanisms in sensitivity analyses. 


## Session Information {.smaller}

```{r}
session_info()
```

